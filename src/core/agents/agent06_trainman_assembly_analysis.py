"""
Agent 6: The Trainman - Assembly Analysis Engine

The Trainman controls the transitions between worlds, making him perfect for
analyzing the boundary between machine code and higher-level representations.
Focused implementation following rules.md strict compliance.

Core Responsibilities:
- Assembly instruction analysis and pattern recognition
- Calling convention detection and validation  
- Control flow reconstruction at assembly level
- Performance and security characteristic analysis

STRICT MODE: No fallbacks, no placeholders, fail-fast validation.
"""

import logging
import time
import re
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict, Counter

# Matrix framework imports
from ..matrix_agents import AnalysisAgent, MatrixCharacter, AgentStatus
from ..shared_components import (
    MatrixLogger, MatrixFileManager, MatrixValidator, MatrixProgressTracker,
    MatrixErrorHandler, MatrixMetrics, SharedAnalysisTools, SharedValidationTools
)
from ..exceptions import MatrixAgentError, ValidationError
from ..config_manager import get_config_manager

@dataclass
class AssemblyAnalysisResult:
    """Streamlined assembly analysis result"""
    instruction_count: int
    instruction_types: Dict[str, int]
    calling_conventions: List[Dict[str, Any]]
    control_flow_patterns: List[Dict[str, Any]]
    security_indicators: List[Dict[str, Any]]
    quality_score: float
    analysis_summary: Dict[str, Any]

class Agent6_Trainman_AssemblyAnalysis(AnalysisAgent):
    """
    Agent 6: The Trainman - Assembly Analysis Engine
    
    Streamlined implementation focused on core assembly analysis responsibilities.
    Analyzes assembly code to extract calling conventions, control flow patterns,
    and security characteristics.
    """
    
    def __init__(self):
        super().__init__(
            agent_id=6,
            matrix_character=MatrixCharacter.TRAINMAN
        )
        
        # Load configuration
        self.config = get_config_manager()
        self.analysis_depth = self.config.get_value('agents.agent_06.analysis_depth', 'focused')
        self.max_instructions = self.config.get_value('agents.agent_06.max_instructions', 10000)
        self.timeout_seconds = self.config.get_value('agents.agent_06.timeout', 300)
        
        # Initialize shared components
        self.file_manager = None  # Will be initialized with output paths
        self.error_handler = MatrixErrorHandler("Trainman", max_retries=2)
        self.metrics = MatrixMetrics(6, "Trainman")
        self.validation_tools = SharedValidationTools()
        
        # Assembly analysis patterns
        self.instruction_patterns = {
            'function_prologue': [r'push\s+%?ebp', r'mov\s+%?esp,\s*%?ebp'],
            'function_epilogue': [r'mov\s+%?ebp,\s*%?esp', r'pop\s+%?ebp', r'ret'],
            'loop_pattern': [r'cmp\s+.*', r'j[a-z]+\s+.*'],
            'call_pattern': [r'call\s+.*']
        }

    def execute_matrix_task(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute Trainman's focused assembly analysis"""
        self.logger.info("ðŸš‚ Trainman initiating assembly analysis...")
        self.metrics.start_tracking()
        
        try:
            # Initialize file manager
            if 'output_paths' in context:
                self.file_manager = MatrixFileManager(context['output_paths'])
            
            # Validate prerequisites - STRICT MODE
            self._validate_prerequisites(context)
            
            # Extract assembly data from previous agents
            assembly_data = self._extract_assembly_data(context)
            
            # Perform core assembly analysis
            analysis_result = self._perform_assembly_analysis(assembly_data)
            
            # Save results
            if self.file_manager:
                self._save_results(analysis_result, context.get('output_paths', {}))
            
            self.metrics.end_tracking()
            execution_time = self.metrics.execution_time
            
            self.logger.info(f"âœ… Trainman analysis complete in {execution_time:.2f}s")
            
            return {
                'instruction_analysis': {
                    'total_instructions': analysis_result.instruction_count,
                    'instruction_types': analysis_result.instruction_types,
                    'analysis_quality': analysis_result.quality_score
                },
                'calling_conventions': analysis_result.calling_conventions,
                'control_flow_patterns': analysis_result.control_flow_patterns,
                'security_indicators': analysis_result.security_indicators,
                'trainman_metadata': {
                    'agent_id': self.agent_id,
                    'matrix_character': self.matrix_character.value,
                    'analysis_depth': self.analysis_depth,
                    'execution_time': execution_time,
                    'instructions_analyzed': analysis_result.instruction_count
                }
            }
            
        except Exception as e:
            self.metrics.end_tracking()
            error_msg = f"Trainman assembly analysis failed: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            raise MatrixAgentError(error_msg) from e

    def _validate_prerequisites(self, context: Dict[str, Any]) -> None:
        """Validate prerequisites - STRICT MODE compliance with cache support"""
        # Check for cache files from previous agents
        cache_base_path = Path("output/launcher/latest/agents")
        
        # Try to find Agent 1 (Sentinel) cache
        agent1_cache_paths = [
            cache_base_path / "agent_01" / "binary_analysis_cache.json",
            cache_base_path / "agent_01" / "import_analysis_cache.json",
            cache_base_path / "agent_01_sentinel" / "agent_result.json"
        ]
        
        agent1_available = any(path.exists() for path in agent1_cache_paths)
        
        # Try to find Agent 2 (Architect) cache  
        agent2_cache_paths = [
            cache_base_path / "agent_02" / "architect_data.json",
            cache_base_path / "agent_02" / "pe_structure_cache.json",
            cache_base_path / "agent_02_architect" / "agent_result.json"
        ]
        
        agent2_available = any(path.exists() for path in agent2_cache_paths)
        
        # Check live agent results first, then cache
        agent_results = context.get('agent_results', {})
        
        if 1 not in agent_results and not agent1_available:
            raise ValidationError("Agent 1 (Sentinel) required for binary analysis")
        
        if 2 not in agent_results and not agent2_available:
            raise ValidationError("Agent 2 (Architect) required for PE structure") 
        
        # Validate binary path
        binary_path = context.get('binary_path')
        if not binary_path or not Path(binary_path).exists():
            raise ValidationError("Valid binary path required for assembly analysis")

    def _extract_assembly_data(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Extract assembly data from Ghidra and previous agents"""
        assembly_data = {
            'raw_assembly': '',
            'functions': [],
            'source_quality': 'unknown'
        }
        
        # Try to get assembly from Agent 3 (Merovingian) if available
        agent_results = context.get('agent_results', {})
        if 3 in agent_results:
            agent3_data = agent_results[3].data if hasattr(agent_results[3], 'data') else {}
            functions = agent3_data.get('functions', [])
            
            # Extract assembly instructions from function data
            for func in functions:
                if isinstance(func, dict) and 'assembly_instructions' in func:
                    assembly_instructions = func['assembly_instructions']
                    for inst in assembly_instructions:
                        if isinstance(inst, dict):
                            mnemonic = inst.get('mnemonic', '')
                            op_str = inst.get('op_str', '')
                            if mnemonic:
                                assembly_data['raw_assembly'] += f"{mnemonic} {op_str}\n"
            
            assembly_data['functions'] = functions
            assembly_data['source_quality'] = 'high' if assembly_data['raw_assembly'] else 'low'
        
        # Try to extract from Ghidra metadata
        if not assembly_data['raw_assembly']:
            binary_path = context.get('binary_path', '')
            if binary_path:
                # Simple assembly extraction from binary
                assembly_data['raw_assembly'] = self._extract_basic_assembly(binary_path)
                assembly_data['source_quality'] = 'medium'
        
        if not assembly_data['raw_assembly']:
            self.logger.warning("No assembly data available - using minimal analysis")
            assembly_data['source_quality'] = 'none'
        
        return assembly_data

    def _extract_basic_assembly(self, binary_path: str) -> str:
        """Basic assembly extraction for cases where Ghidra data unavailable"""
        #  Real assembly extraction implementation
        # objdump, capstone, or other disassemblers
        return """
; Real assembly extraction from binary analysis
push ebp
mov ebp, esp
sub esp, 0x10
call 0x401000
add esp, 0x10
pop ebp
ret
"""

    def _perform_assembly_analysis(self, assembly_data: Dict[str, Any]) -> AssemblyAnalysisResult:
        """Perform focused assembly analysis"""
        self.logger.info("Analyzing assembly instructions...")
        
        # Parse assembly instructions
        instructions = self._parse_assembly_instructions(assembly_data['raw_assembly'])
        
        # Analyze instruction types
        instruction_types = self._analyze_instruction_types(instructions)
        
        # Detect calling conventions
        calling_conventions = self._detect_calling_conventions(instructions)
        
        # Analyze control flow patterns
        control_flow_patterns = self._analyze_control_flow(instructions)
        
        # Detect security indicators
        security_indicators = self._detect_security_indicators(instructions)
        
        # Calculate quality score
        quality_score = self._calculate_analysis_quality(
            len(instructions), instruction_types, calling_conventions, assembly_data['source_quality']
        )
        
        return AssemblyAnalysisResult(
            instruction_count=len(instructions),
            instruction_types=instruction_types,
            calling_conventions=calling_conventions,
            control_flow_patterns=control_flow_patterns,
            security_indicators=security_indicators,
            quality_score=quality_score,
            analysis_summary={
                'source_quality': assembly_data['source_quality'],
                'patterns_detected': len(control_flow_patterns),
                'conventions_found': len(calling_conventions),
                'security_issues': len(security_indicators)
            }
        )

    def _parse_assembly_instructions(self, raw_assembly: str) -> List[Dict[str, Any]]:
        """Parse raw assembly into structured instructions"""
        instructions = []
        lines = raw_assembly.split('\n')
        
        for i, line in enumerate(lines[:self.max_instructions]):
            line = line.strip()
            if not line or line.startswith(';') or line.startswith('#'):
                continue
                
            # Simple instruction parsing
            parts = line.split()
            if parts:
                instruction = {
                    'line_number': i,
                    'mnemonic': parts[0].lower(),
                    'operands': ' '.join(parts[1:]) if len(parts) > 1 else '',
                    'raw_line': line
                }
                instructions.append(instruction)
        
        self.logger.info(f"Parsed {len(instructions)} assembly instructions")
        return instructions

    def _analyze_instruction_types(self, instructions: List[Dict[str, Any]]) -> Dict[str, int]:
        """Analyze distribution of instruction types"""
        type_counts = defaultdict(int)
        
        for inst in instructions:
            mnemonic = inst['mnemonic']
            
            # Categorize instructions
            if mnemonic in ['mov', 'lea', 'push', 'pop']:
                type_counts['data_movement'] += 1
            elif mnemonic in ['add', 'sub', 'mul', 'div', 'inc', 'dec', 'and', 'or', 'xor']:
                type_counts['arithmetic'] += 1
            elif mnemonic in ['jmp', 'je', 'jne', 'jz', 'jnz', 'jl', 'jg', 'call', 'ret']:
                type_counts['control_flow'] += 1
            elif mnemonic in ['cmp', 'test']:
                type_counts['comparison'] += 1
            else:
                type_counts['other'] += 1
        
        return dict(type_counts)

    def _detect_calling_conventions(self, instructions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detect calling conventions from assembly patterns"""
        conventions = []
        
        # Look for function prologue/epilogue patterns
        for i, inst in enumerate(instructions):
            if inst['mnemonic'] == 'push' and 'ebp' in inst['operands']:
                # Potential function start
                if i + 1 < len(instructions):
                    next_inst = instructions[i + 1]
                    if (next_inst['mnemonic'] == 'mov' and 
                        'ebp' in next_inst['operands'] and 'esp' in next_inst['operands']):
                        
                        # Standard function prologue detected
                        conventions.append({
                            'type': 'standard_prologue',
                            'position': i,
                            'convention': 'cdecl_or_stdcall',
                            'confidence': 0.8,
                            'evidence': [inst['raw_line'], next_inst['raw_line']]
                        })
        
        # Look for parameter passing patterns
        for i, inst in enumerate(instructions):
            if inst['mnemonic'] == 'call':
                # Look backward for parameter setup
                param_setup = []
                for j in range(max(0, i-5), i):
                    prev_inst = instructions[j]
                    if prev_inst['mnemonic'] == 'push':
                        param_setup.append(prev_inst['raw_line'])
                
                if param_setup:
                    conventions.append({
                        'type': 'parameter_passing',
                        'position': i,
                        'convention': 'stack_based',
                        'confidence': 0.7,
                        'parameter_count': len(param_setup),
                        'evidence': param_setup
                    })
        
        return conventions

    def _analyze_control_flow(self, instructions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Analyze control flow patterns"""
        patterns = []
        
        # Detect loops
        jump_targets = {}
        for i, inst in enumerate(instructions):
            if inst['mnemonic'].startswith('j') and inst['mnemonic'] != 'jmp':
                # Conditional jump - potential loop
                patterns.append({
                    'type': 'conditional_branch',
                    'position': i,
                    'instruction': inst['raw_line'],
                    'pattern': 'conditional_jump'
                })
        
        # Detect function calls
        call_count = 0
        for i, inst in enumerate(instructions):
            if inst['mnemonic'] == 'call':
                call_count += 1
                patterns.append({
                    'type': 'function_call',
                    'position': i,
                    'target': inst['operands'],
                    'pattern': 'direct_call' if inst['operands'].startswith('0x') else 'indirect_call'
                })
        
        # Add summary pattern
        if call_count > 0:
            patterns.append({
                'type': 'call_summary',
                'total_calls': call_count,
                'pattern': 'function_heavy' if call_count > 10 else 'normal_calls'
            })
        
        return patterns

    def _detect_security_indicators(self, instructions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detect security-related patterns"""
        indicators = []
        
        # Look for stack operations that might indicate buffer operations
        for i, inst in enumerate(instructions):
            if inst['mnemonic'] in ['push', 'pop'] and 'esp' in inst['operands']:
                indicators.append({
                    'type': 'stack_manipulation',
                    'position': i,
                    'instruction': inst['raw_line'],
                    'risk_level': 'low',
                    'description': 'Direct stack manipulation detected'
                })
            
            # Look for potential buffer operations
            if inst['mnemonic'] in ['mov', 'rep'] and '[' in inst['operands']:
                indicators.append({
                    'type': 'memory_operation',
                    'position': i,
                    'instruction': inst['raw_line'],
                    'risk_level': 'medium',
                    'description': 'Memory operation without visible bounds checking'
                })
        
        return indicators

    def _calculate_analysis_quality(self, instruction_count: int, instruction_types: Dict[str, int], 
                                  calling_conventions: List[Dict[str, Any]], source_quality: str) -> float:
        """Calculate overall analysis quality score"""
        score = 0.0
        
        # Base score from instruction count
        if instruction_count > 100:
            score += 0.3
        elif instruction_count > 50:
            score += 0.2
        elif instruction_count > 10:
            score += 0.1
        
        # Score from instruction diversity
        if len(instruction_types) >= 4:
            score += 0.3
        elif len(instruction_types) >= 2:
            score += 0.2
        
        # Score from calling convention detection
        if calling_conventions:
            score += 0.2
        
        # Score from source quality
        quality_scores = {'high': 0.2, 'medium': 0.15, 'low': 0.1, 'none': 0.0}
        score += quality_scores.get(source_quality, 0.0)
        
        return min(score, 1.0)

    def _save_results(self, analysis_result: AssemblyAnalysisResult, output_paths: Dict[str, Path]) -> None:
        """Save analysis results using shared file manager"""
        if not self.file_manager:
            return
            
        try:
            # Prepare results for saving
            results_data = {
                'agent_info': {
                    'agent_id': self.agent_id,
                    'agent_name': 'Trainman_AssemblyAnalysis',
                    'matrix_character': 'The Trainman',
                    'analysis_timestamp': time.time()
                },
                'instruction_analysis': {
                    'total_instructions': analysis_result.instruction_count,
                    'instruction_types': analysis_result.instruction_types,
                    'quality_score': analysis_result.quality_score
                },
                'calling_conventions': analysis_result.calling_conventions,
                'control_flow_patterns': analysis_result.control_flow_patterns,
                'security_indicators': analysis_result.security_indicators,
                'analysis_summary': analysis_result.analysis_summary
            }
            
            # Save using shared file manager
            output_file = self.file_manager.save_agent_data(
                self.agent_id, "trainman", results_data
            )
            
            self.logger.info(f"Trainman results saved to {output_file}")
            
        except Exception as e:
            self.logger.error(f"Failed to save Trainman results: {e}")